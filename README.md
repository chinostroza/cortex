<div align="center"\>
<img src="logo.png" alt="CÃ³rtex Logo" width="200"/\>
</div\>

# ğŸ§  CÃ³rtex: Tu AI Gateway de ProducciÃ³n

**Un gateway de inferencia inteligente y resiliente para tus aplicaciones de IA. Construido para ofrecer fiabilidad, control de costos y alto rendimiento a escala.**

CÃ³rtex es un **AI Gateway** de cÃ³digo abierto construido sobre **Elixir** y **Phoenix**. Su misiÃ³n es actuar como una capa de enrutamiento robusta entre tu aplicaciÃ³n y mÃºltiples proveedores de modelos de IA, garantizando que tus servicios se mantengan disponibles, rÃ¡pidos y rentables.

-----

## ğŸ¤” Â¿Por quÃ© un AI Gateway?

Construir una aplicaciÃ³n de IA puede llevar minutos. Sin embargo, llevarla a producciÃ³n requiere **fiabilidad y estabilidad a escala**. Conectar una aplicaciÃ³n directamente a un Ãºnico proveedor de LLM crea una dependencia frÃ¡gil: si ese proveedor sufre una caÃ­da o alcanzas sus lÃ­mites de tasa, tu aplicaciÃ³n tambiÃ©n lo harÃ¡.

CÃ³rtex resuelve este problema al proporcionar una capa unificada que garantiza la disponibilidad cuando un proveedor falla, evita los bajos lÃ­mites de tasa y ofrece una fiabilidad constante para las cargas de trabajo de IA.

-----

## âœ¨ CaracterÃ­sticas Principales

  * **Resiliencia Multi-Proveedor ğŸŒ:** Soporte nativo para **Ollama**, **Groq**, **Gemini** y **Cohere**. Si un proveedor falla, CÃ³rtex redirige el trÃ¡fico al siguiente disponible de forma automÃ¡tica.
  * **Balanceo de Carga y Worker Pools Inteligentes ğŸŠ:** Gestiona un pool de workers con chequeos de salud (health checks), priorizaciÃ³n y tolerancia a fallos para garantizar que siempre se utilice el recurso mÃ¡s Ã³ptimo.
  * **GestiÃ³n y RotaciÃ³n AutomÃ¡tica de API Keys ğŸ”‘:** Administra mÃºltiples API keys por proveedor con estrategias de rotaciÃ³n (round-robin, least-used) para maximizar el uso de las cuotas gratuitas y evitar bloqueos.
  * **Manejo DinÃ¡mico de LÃ­mites de Tasa (Rate Limiting) â±ï¸:** Detecta automÃ¡ticamente los errores de lÃ­mite de tasa, bloquea temporalmente la API key afectada y rota a la siguiente, manteniendo la aplicaciÃ³n en funcionamiento.
  * **Streaming de Baja Latencia ğŸŒŠ:** ImplementaciÃ³n completa de Server-Sent Events (SSE) para entregar respuestas en tiempo real desde cualquier proveedor, mejorando la experiencia del usuario.
  * **Tolerancia a Fallos Superior ğŸ’ª:** Construido sobre la plataforma Elixir/OTP, CÃ³rtex aprovecha la supervisiÃ³n jerÃ¡rquica y la recuperaciÃ³n automÃ¡tica para una estabilidad a nivel de producciÃ³n.
  * **Arquitectura Limpia y Extensible ğŸ—ï¸:** DiseÃ±ado siguiendo los principios SOLID, lo que facilita la adiciÃ³n de nuevos proveedores de IA sin modificar el cÃ³digo existente.

-----

## ğŸ“® Arquitectura y Flujo de Peticiones

CÃ³rtex actÃºa como un director de orquesta inteligente para tus peticiones de IA:

1.  **Entrada (`Phoenix Router`) ğŸ§‘â€ğŸ’¼:** Recibe la peticiÃ³n (`POST /api/chat`) de tu aplicaciÃ³n cliente.
2.  **Controlador (`Controller`) ğŸ­:** Prepara la conexiÃ³n de streaming y solicita un worker disponible al `Worker Pool`.
3.  **SelecciÃ³n de Worker (`Pool`) ğŸŠ:** El pool manager evalÃºa la salud y prioridad de todos los workers registrados y selecciona el mejor candidato para procesar la peticiÃ³n.
      * **Worker Ollama** (Prioridad 10): Tu modelo local, siempre la primera opciÃ³n para costo cero ğŸ .
      * **Worker Groq** (Prioridad 20): El especialista en velocidad con LPUs âš¡.
      * **Worker Gemini** (Prioridad 30): El potente y equilibrado modelo de Google ğŸ§ .
      * **Worker Cohere** (Prioridad 40): El especialista en conversaciones de nivel empresarial ğŸ’¬.
4.  **EjecuciÃ³n y GestiÃ³n de API Keys (`API Key Manager`)** ğŸ”‘: El worker seleccionado solicita una API key vÃ¡lida al gestor, que la proporciona segÃºn la estrategia de rotaciÃ³n configurada.
5.  **Respuesta en Tiempo Real (`Streaming`)** ğŸ¼: El resultado se transmite de vuelta al cliente en tiempo real, token por token.

### ğŸ¯ **LÃ³gica de Failover en Cascada**

El sistema estÃ¡ diseÃ±ado para que el show siempre continÃºe:

  * Si tu servidor **Ollama** estÃ¡ caÃ­do o sobrecargado â†’ CÃ³rtex utiliza **Groq** automÃ¡ticamente.
  * Si **Groq** alcanza sus lÃ­mites de tasa â†’ CÃ³rtex rota a otra API key de Groq o salta a **Gemini**.
  * Si todos los proveedores primarios fallan â†’ **Cohere** actÃºa como respaldo final.

-----

## ğŸ› ï¸ InstalaciÃ³n y Primeros Pasos

Â¡Manos a la obra\! Para tener CÃ³rtex funcionando en tu mÃ¡quina.

#### **Requisitos Previos**

AsegÃºrate de tener:

  * [Elixir](https://elixir-lang.org/install.html) instalado.
  * [Ollama](https://ollama.com/) instalado y funcionando.
  * Git para clonar el proyecto.

#### **Pasos**

1.  **Clona el Repositorio:**

    ```bash
    git clone [https://github.com/tu-usuario/cortex.git](https://github.com/tu-usuario/cortex.git)
    cd cortex
    ```

2.  **Instala las Dependencias de Elixir:**

    ```bash
    mix deps.get
    ```

3.  **Configura tus Variables de Entorno:**

      * Crea tu archivo de configuraciÃ³n personal copiando el ejemplo:
        ```bash
        cp .env.example .env
        ```
      * Abre el archivo `.env` y configÃºralo con tus API keys reales.
      * **âš ï¸ Importante:** El archivo `.env` estÃ¡ incluido en `.gitignore` para proteger tus credenciales.

4.  **Â¡Lanzamiento\!** ğŸš€

      * **En una terminal**, inicia tu servidor de Ollama:
        ```bash
        ollama serve
        ```
      * **En otra terminal**, inicia el gateway CÃ³rtex:
        ```bash
        mix phx.server
        ```

Â¡Listo\! Tu AI Gateway CÃ³rtex estÃ¡ ahora escuchando en `http://localhost:4000`.

-----

## âš™ï¸ ConfiguraciÃ³n Multi-Provider

Configura tus proveedores y estrategias a travÃ©s de variables de entorno.

```bash
# === PROVEEDORES DE IA ===
# Separa mÃºltiples claves con comas para habilitar la rotaciÃ³n
GROQ_API_KEYS=gsk_key1,gsk_key2
GEMINI_API_KEYS=AIza_key1,AIza_key2
COHERE_API_KEYS=co_key1

# Modelos a usar (opcional, usa los predeterminados si no se especifica)
GROQ_MODEL=llama-3.1-8b-instant
GEMINI_MODEL=gemini-1.5-flash
COHERE_MODEL=command-r

# === OLLAMA (LOCAL) ===
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# === CONFIGURACIÃ“N AVANZADA DEL GATEWAY ===
API_KEY_ROTATION_STRATEGY=round_robin  # Opciones: round_robin, least_used, random
RATE_LIMIT_BLOCK_MINUTES=15           # Tiempo que una key bloqueada por rate limit permanece inactiva
HEALTH_CHECK_INTERVAL=60              # Intervalo en segundos para los chequeos de salud de los workers
```

### ğŸ¯ **Estrategias de RotaciÃ³n de API Keys**

  - **`round_robin`**: Rota las claves en orden secuencial. Ideal para una distribuciÃ³n uniforme.
  - **`least_used`**: Selecciona la clave que ha procesado menos peticiones.
  - **`random`**: SelecciÃ³n aleatoria para evitar patrones predecibles.

-----

## ğŸ® Modo de Uso

InteractÃºa con CÃ³rtex como lo harÃ­as con una API de OpenAI, pero apuntando a tu endpoint local.

### ğŸš€ **Prueba RÃ¡pida con cURL**

```bash
curl -N -X POST http://localhost:4000/api/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [
    {
      "role": "user",
      "content": "Explica quÃ© es un AI Gateway en una frase"
    }
  ]
}'
```

DeberÃ­as ver la respuesta generÃ¡ndose en tiempo real. Si Ollama no responde, CÃ³rtex cambiarÃ¡ automÃ¡ticamente a Groq o al siguiente proveedor disponible.

### ğŸ“Š **Endpoints de Monitoreo**

CÃ³rtex proporciona endpoints para observar el estado del sistema en tiempo real:

```bash
# Ver el estado de salud de todos los workers
curl http://localhost:4000/api/health

# Ver estadÃ­sticas de uso de las API keys
curl http://localhost:4000/api/stats

# Ver la lista de workers disponibles y su prioridad
curl http://localhost:4000/api/workers
```

-----

## ğŸ—ºï¸ Roadmap

### âœ… **Completado**

  - [x] ğŸŒ **Arquitectura Multi-Proveedor:** Soporte para Ollama, Groq, Gemini y Cohere.
  - [x] ğŸ”‘ **Gestor de API Keys:** RotaciÃ³n inteligente con mÃºltiples estrategias.
  - [x] ğŸŠ **Worker Pool Resiliente:** Sistema robusto con health checks y failover.
  - [x] ğŸŒŠ **Streaming Unificado:** Server-Sent Events para todos los proveedores.
  - [x] âš¡ **Manejo de Rate Limits:** DetecciÃ³n automÃ¡tica y rotaciÃ³n de claves.
  - [x] ğŸ§ª **Cobertura de Pruebas:** MÃ¡s de 70 pruebas automatizadas para garantizar la calidad.

### ğŸ”® **PrÃ³ximas Mejoras**

  - [ ] ğŸ§  **CachÃ© Inteligente:** Implementar cachÃ© en ETS para respuestas comunes y reducir la latencia.
  - [ ] ğŸ“Š **Dashboard LiveView:** Un panel de control en tiempo real para monitorear el trÃ¡fico y el estado de los workers.
  - [ ] ğŸ—ºï¸ **Enrutamiento por Contenido:** Un "router de IA" que seleccione el mejor modelo segÃºn la tarea (ej. codificaciÃ³n, escritura creativa).
  - [ ] ğŸ”Œ **Soporte para mÃ¡s Proveedores:** AÃ±adir OpenAI, Anthropic, y Mistral.
  - [ ] ğŸ“ˆ **MÃ©tricas Avanzadas:** IntegraciÃ³n con Prometheus y Grafana para observabilidad a nivel de producciÃ³n.

-----

## ğŸ—ï¸ Arquitectura TÃ©cnica Detallada

El diseÃ±o de CÃ³rtex se basa en los principios de software robusto para garantizar la mantenibilidad y escalabilidad.

### ğŸ§¬ **Principios SOLID Implementados**

  - **Single Responsibility**: Cada worker se especializa en un Ãºnico proveedor de IA.
  - **Open/Closed**: Es posible aÃ±adir nuevos proveedores (workers) sin modificar el cÃ³digo del `Pool` o del `Controller`.
  - **Liskov Substitution**: Todos los workers adhieren a un comportamiento comÃºn (`APIWorker`), permitiendo que el `Pool` los trate de forma intercambiable.
  - **Interface Segregation**: Se definen comportamientos especÃ­ficos para tareas como el formateo de mensajes y la gestiÃ³n de streaming.
  - **Dependency Inversion**: Los mÃ³dulos de alto nivel (como el `Pool`) dependen de abstracciones (el `behaviour` de los workers), no de implementaciones concretas.

*(El resto de las secciones de Arquitectura, Testing, Contribuciones y Licencia de tu README original son excelentes y no necesitan cambios significativos).*

-----

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas\! Si tienes una idea o quieres arreglar un bug:

1.  Abre un "Issue" para discutir tu idea.
2.  Haz un "Fork" del repositorio.
3.  Crea una nueva rama (`git checkout -b mi-nueva-feature`).
4.  Haz tus cambios y envÃ­a un "Pull Request".

-----

## ğŸ“œ Licencia

CÃ³rtex se distribuye bajo la licencia **GNU Affero General Public License v3.0 (AGPLv3)**. Esto significa que puedes usarlo, modificarlo y distribuirlo libremente. Si lo utilizas para potenciar un servicio accesible a travÃ©s de una red, la licencia requiere que el cÃ³digo fuente completo de tu servicio tambiÃ©n sea pÃºblico.

Puedes leer la licencia completa [aquÃ­](https://www.gnu.org/licenses/agpl-3.0.html).

-----

## ğŸ’¼ Licencia Comercial

Si las condiciones de la licencia AGPLv3 no son compatibles con tu modelo de negocio (por ejemplo, si deseas ofrecer CÃ³rtex como un servicio de cÃ³digo cerrado), es posible adquirir una licencia comercial.

Para mÃ¡s detalles, por favor contacta a **Carlos Hinostroza** en **c@zea.cl**.