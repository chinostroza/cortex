<div align="center">
  <img src="logo.png" alt="CÃ³rtex Logo" width="200"/>
</div>

# ğŸ§  CÃ³rtex

**Tu propio cerebro para orquestar mÃºltiples modelos de IA al mÃ­nimo costo.**

CÃ³rtex es un gateway de inferencia y un balanceador de carga inteligente construido sobre **Elixir** y **Phoenix**. Su misiÃ³n es permitir a los desarrolladores construir aplicaciones de IA robustas con un presupuesto cercano a cero, ofreciendo un modelo de doble licencia para dar soporte tanto a la comunidad open-source como a las necesidades comerciales.

---

## ğŸ¤” Â¿Por quÃ© existe CÃ³rtex?

Las APIs de IA son increÃ­bles, Â¡pero pueden costar un ojo de la cara ğŸ’¸! CÃ³rtex resuelve este problema creando un "cerebro" central que gestiona de forma inteligente tus recursos de IA, priorizando siempre las opciones gratuitas o locales. Â¡Construye sin miedo a la factura!

---

## âœ¨ CaracterÃ­sticas Principales

* **Arquitectura Multi-Provider ğŸŒ:** Soporte nativo para **Ollama**, **Gemini**, **Cohere** y **Groq** con failover automÃ¡tico.
* **Worker Pool Inteligente ğŸŠ:** Sistema de workers con health checks, priorizaciÃ³n automÃ¡tica y tolerancia a fallos.
* **RotaciÃ³n Inteligente de API Keys ğŸ”‘:** Manager avanzado con estrategias round-robin, least-used y random para maximizar el uso de APIs gratuitas.
* **Rate Limiting AutomÃ¡tico â±ï¸:** DetecciÃ³n y manejo automÃ¡tico de lÃ­mites de API con bloqueo temporal y rotaciÃ³n.
* **Streaming Real ğŸŒŠ:** ImplementaciÃ³n completa de Server-Sent Events para respuestas en tiempo real de todos los providers.
* **Tolerancia a Fallos Nivel DIOS ğŸ’ª:** Construido sobre Elixir/OTP con supervisiÃ³n jerÃ¡rquica y recuperaciÃ³n automÃ¡tica.
* **Failover en Cascada ğŸ¯:** Si un provider falla, automÃ¡ticamente usa el siguiente disponible segÃºn prioridad.
* **Arquitectura SOLID ğŸ—ï¸:** CÃ³digo limpio siguiendo principios de responsabilidad Ãºnica y alta cohesiÃ³n.

---

## ğŸ“® Â¿CÃ³mo Funciona? Â¡La Orquesta de IA!

Imagina que CÃ³rtex es una orquesta sinfÃ³nica donde cada mÃºsico es un proveedor de IA:

1.  **El Recepcionista (`Router`) ğŸ§‘â€ğŸ’¼:** Recibe tu peticiÃ³n (`POST /api/chat`) y la dirige al Director.
2.  **El Director (`Controller`) ğŸ­:** Prepara el concierto (streaming connection) y llama al Pool de Workers.
3.  **El Pool Manager (`Pool`) ğŸŠ:** EvalÃºa quÃ© workers estÃ¡n disponibles y selecciona el mejor segÃºn prioridad y salud.
4.  **Los MÃºsicos (`Workers`) ğŸµ:** 
   - **Ollama Worker** (Prioridad 10): Tu orquesta local, siempre la primera opciÃ³n ğŸ 
   - **Groq Worker** (Prioridad 20): El velocista ultrarrÃ¡pido con LPUs âš¡
   - **Gemini Worker** (Prioridad 30): El equilibrado de Google ğŸ§ 
   - **Cohere Worker** (Prioridad 40): El especialista en conversaciones ğŸ’¬
5.  **El API Key Manager** ğŸ”‘: Asegura que cada mÃºsico tenga sus "instrumentos" (API keys) listos y rota automÃ¡ticamente cuando hay problemas.
6.  **La Respuesta** ğŸ¼: El resultado llega como streaming en tiempo real, nota por nota.

### ğŸ¯ **Failover Inteligente**
Si tu servidor Ollama estÃ¡ ocupado â†’ automÃ¡ticamente usa Groq  
Si Groq alcanza sus lÃ­mites â†’ rota a la siguiente API key o usa Gemini  
Si todo falla â†’ Cohere al rescate  
**Â¡El show siempre continÃºa!** ğŸª

---

## ğŸ› ï¸ InstalaciÃ³n y Primeros Pasos

Â¡Manos a la obra! Para tener CÃ³rtex funcionando en tu mÃ¡quina.

### ğŸ³ **OpciÃ³n 1: Docker (Recomendado - MÃ¡s FÃ¡cil)**

La forma mÃ¡s rÃ¡pida de ejecutar CÃ³rtex es con Docker:

#### **Requisitos Previos**
* [Docker](https://docs.docker.com/get-docker/) instalado
* Git para clonar el proyecto

#### **Pasos**

1.  **Clona el Repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/cortex.git
    cd cortex
    ```

2.  **Configura tus API Keys:**
    ```bash
    cp .env.example .env
    nano .env  # Edita y agrega tus API keys
    ```

3.  **Â¡Lanzamiento con Docker Compose! ğŸš€**
    ```bash
    docker-compose up -d
    ```

4.  **Verifica que estÃ© funcionando:**
    ```bash
    curl http://localhost:4000/api/health
    ```

Â¡Listo! Tu gateway CÃ³rtex estÃ¡ corriendo en `http://localhost:4000`.

**Ver mÃ¡s detalles en [DOCKER.md](DOCKER.md)**

---

### ğŸ’» **OpciÃ³n 2: InstalaciÃ³n Local (Para Desarrollo)**

Si prefieres instalar localmente o desarrollar:

#### **Requisitos Previos**

AsegÃºrate de tener:
* [Elixir 1.15+](https://elixir-lang.org/install.html) instalado
* [Ollama](https://ollama.com/) instalado y funcionando (opcional)
* Git para clonar el proyecto

#### **Pasos**

1.  **Clona el Repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/cortex.git
    cd cortex
    ```

2.  **InstalaciÃ³n AutomÃ¡tica:**
    ```bash
    ./setup_cortex.sh
    ```
    
    O manualmente:
    ```bash
    mix deps.get
    cp .env.example .env
    nano .env  # Configura tus API keys
    ```

3.  **Â¡Lanzamiento! ğŸš€**
    ```bash
    # OpciÃ³n 1: Script de inicio
    ./quick_start.sh
    
    # OpciÃ³n 2: Comando directo
    mix phx.server
    
    # OpciÃ³n 3: Con consola interactiva
    iex -S mix phx.server
    ```

Â¡Listo! Tu gateway CÃ³rtex estÃ¡ ahora escuchando en `http://localhost:4000`.

**Ver guÃ­a completa en [INSTALL.md](INSTALL.md)**

---

## âš™ï¸ ConfiguraciÃ³n Multi-Provider

CÃ³rtex ahora soporta mÃºltiples proveedores de IA con configuraciÃ³n flexible:

### ğŸ”§ **Variables de Entorno**

```bash
# API Keys para providers de IA
export GROQ_API_KEYS=your_groq_api_key_here
export GEMINI_API_KEYS=your_gemini_api_key_here  
export COHERE_API_KEYS=your_cohere_api_key_here

# Modelos a usar (opcional)
export GROQ_MODEL=llama-3.1-8b-instant
export GEMINI_MODEL=gemini-2.0-flash-001
export COHERE_MODEL=command-light

# Ollama local (opcional - backup ilimitado)
export OLLAMA_BASE_URL=http://localhost:11434
export OLLAMA_MODEL=gemma3:4b

# === GROQ (Ultra rÃ¡pido) ===
GROQ_API_KEYS=gsk_key1,gsk_key2,gsk_key3
GROQ_MODEL=llama-3.1-8b-instant

# === GOOGLE GEMINI ===  
GEMINI_API_KEYS=AIza_key1,AIza_key2
GEMINI_MODEL=gemini-2.0-flash-001

# === COHERE ===
COHERE_API_KEYS=co_key1,co_key2
COHERE_MODEL=command

# === CONFIGURACIÃ“N AVANZADA ===
API_KEY_ROTATION_STRATEGY=round_robin  # round_robin, least_used, random
RATE_LIMIT_BLOCK_MINUTES=15           # Tiempo de bloqueo por rate limit
HEALTH_CHECK_INTERVAL=60              # Segundos entre health checks
```

### ğŸ¯ **Estrategias de RotaciÃ³n**

- **`round_robin`**: Rota API keys en orden secuencial
- **`least_used`**: Usa la key menos utilizada
- **`random`**: SelecciÃ³n aleatoria para distribuciÃ³n uniforme

### ğŸ¥ **Health Checks AutomÃ¡ticos**

Cada worker verifica automÃ¡ticamente:
- âœ… Conectividad con el API
- âœ… Rate limits disponibles  
- âœ… Latencia de respuesta
- âœ… Estado de las API keys

---

## ğŸ® Modo de Uso

### ğŸš€ **Prueba RÃ¡pida**

EnvÃ­a una peticiÃ³n con streaming en tiempo real:

```bash
curl -N -X POST http://localhost:4000/api/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [
    {
      "role": "user", 
      "content": "Explica la arquitectura de CÃ³rtex en 3 lÃ­neas"
    }
  ]
}'
```

### ğŸ”¥ **Ejemplo Avanzado con ParÃ¡metros**

```bash
curl -N -X POST http://localhost:4000/api/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [
    {
      "role": "system",
      "content": "Eres un experto en arquitectura de software"
    },
    {
      "role": "user", 
      "content": "Â¿CÃ³mo funciona el failover en sistemas distribuidos?"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 1000,
  "model": "groq"
}'
```

### ğŸ“Š **Monitoreo en Tiempo Real**

```bash
# Ver estado de workers
curl http://localhost:4000/api/health

# Ver estadÃ­sticas de API keys  
curl http://localhost:4000/api/stats

# Ver workers disponibles
curl http://localhost:4000/api/workers
```

### ğŸ³ **Comandos Docker Ãštiles**

```bash
# Ver logs en tiempo real
docker-compose logs -f

# Reiniciar Cortex
docker-compose restart

# Detener servicios
docker-compose down

# Actualizar imagen
docker-compose build && docker-compose up -d
```

**DeberÃ­as ver la respuesta escribiÃ©ndose palabra por palabra.** Si Ollama estÃ¡ ocupado, automÃ¡ticamente switchea a Groq, Gemini o Cohere. Â¡Magia multi-provider! âœ¨

-----

## ğŸ—ºï¸ Roadmap (Nuestros PrÃ³ximos Hechizos)

### âœ… **Completado en v2.0**
- [x] ğŸŒ **Arquitectura Multi-Provider:** Soporte para Ollama, Groq, Gemini y Cohere
- [x] ğŸ”‘ **API Key Manager:** RotaciÃ³n inteligente con estrategias mÃºltiples  
- [x] ğŸŠ **Worker Pool:** Sistema robusto con health checks y failover
- [x] ğŸŒŠ **Streaming Real:** Server-Sent Events para todos los providers
- [x] âš¡ **Rate Limiting:** DetecciÃ³n automÃ¡tica y rotaciÃ³n de keys
- [x] ğŸ§ª **Testing:** Cobertura completa con 73+ tests automatizados

### ğŸ¯ **En Desarrollo**
- [ ] ğŸ—ï¸ **Supervisor Updates:** IntegraciÃ³n completa de nuevos workers  
- [ ] ğŸ“– **DocumentaciÃ³n:** GuÃ­as detalladas por proveedor
- [ ] âš™ï¸ **Config Manager:** ConfiguraciÃ³n dinÃ¡mica desde .env

### ğŸ”® **PrÃ³ximos Hechizos**
- [ ] ğŸ§  **CachÃ© Inteligente:** ETS cache para respuestas instantÃ¡neas
- [ ] ğŸ“Š **Dashboard LiveView:** Panel de control en tiempo real 
- [ ] ğŸ—ºï¸ **Enrutamiento por Tarea:** AI que selecciona el mejor modelo automÃ¡ticamente
- [ ] ğŸ”Œ **MÃ¡s Providers:** OpenAI, Anthropic, Mistral, Azure OpenAI
- [ ] ğŸ›ï¸ **Load Balancing:** DistribuciÃ³n inteligente de carga
- [ ] ğŸ“ˆ **MÃ©tricas Avanzadas:** Prometheus + Grafana integration

-----

## ğŸ—ï¸ Arquitectura TÃ©cnica

### ğŸ­ **Componentes Principales**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HTTP Client   â”‚â”€â”€â”€â–¶â”‚  Phoenix Router  â”‚â”€â”€â”€â–¶â”‚  Chat Controller    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Worker Pool                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Ollama    â”‚  â”‚    Groq     â”‚  â”‚   Gemini    â”‚  â”‚   Cohere    â”‚ â”‚
â”‚  â”‚  (Prio 10)  â”‚  â”‚  (Prio 20)  â”‚  â”‚  (Prio 30)  â”‚  â”‚  (Prio 40)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  API Key Manager    â”‚
                        â”‚ âš™ï¸ Round Robin       â”‚
                        â”‚ ğŸ“Š Usage Stats       â”‚
                        â”‚ ğŸš« Rate Limiting     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§¬ **Principios SOLID Implementados**

- **Single Responsibility**: Cada worker maneja un solo proveedor
- **Open/Closed**: FÃ¡cil agregar nuevos providers sin modificar existentes  
- **Liskov Substitution**: Todos los workers implementan el mismo behaviour
- **Interface Segregation**: APIWorkerBase proporciona funcionalidad comÃºn
- **Dependency Inversion**: Pool depende de abstracciones, no implementaciones

### ğŸ§ª **Testing & Calidad**

```bash
# Ejecutar todos los tests
mix test

# Solo tests de workers (sin integraciÃ³n)
mix test test/cortex/workers/adapters/ --exclude integration  

# Tests con coverage
mix test --cover

# Tests de integraciÃ³n con APIs reales (requiere API keys)
mix test --only integration

# Demos interactivos
mix run test_workers_demo.exs
mix run test_api_key_manager_demo.exs
```

**ğŸ“Š Cobertura Actual**: 73+ tests automatizados cubriendo:
- âœ… Todos los workers (Ollama, Groq, Gemini, Cohere)
- âœ… API Key Manager con todas las estrategias 
- âœ… TransformaciÃ³n de mensajes por proveedor
- âœ… ExtracciÃ³n de chunks de streaming
- âœ… Health checks y error handling
- âœ… Rate limiting y failover

-----

## ğŸ¤ Â¿Quieres Ayudar? Â¡Ãšnete a la Magia\!

Â¡Las contribuciones son bienvenidas\! Si tienes una idea o quieres arreglar un bug:

1.  Abre un "Issue" para discutir tu idea.
2.  Haz un "Fork" del repositorio.
3.  Crea una nueva rama (`git checkout -b mi-nueva-feature`).
4.  Haz tus cambios y envÃ­a un "Pull Request".

-----

## ğŸ“œ Licencia

CÃ³rtex se distribuye bajo la licencia **GNU Affero General Public License v3.0 (AGPLv3)**. Esto significa que puedes usarlo, modificarlo y distribuirlo libremente. Si lo utilizas para potenciar un servicio accesible a travÃ©s de una red, la licencia requiere que el cÃ³digo fuente completo de tu servicio tambiÃ©n sea pÃºblico.

Puedes leer la licencia completa [aquÃ­](https://www.gnu.org/licenses/agpl-3.0.html).

-----

## ğŸ’¼ Licencia Comercial

Si las condiciones de la licencia AGPLv3 no son compatibles con tu modelo de negocio (por ejemplo, si deseas ofrecer CÃ³rtex como un servicio de cÃ³digo cerrado), es posible adquirir una licencia comercial.

Para mÃ¡s detalles, por favor contacta a **Carlos Hinostroza** en **c@zea.cl**.